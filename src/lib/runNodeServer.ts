/*
 * Enhanced runFlow():
 *   ‚Äì keeps a ctx.seen array (topics already covered)
 *   ‚Äì recognises `__resume__` sentinel to pick the next pending story node
 *   ‚Äì skips any story node whose tag already appears in ctx.seen
 */
import OpenAI from "openai";
import { FlowEngine } from "@/lib/flowEngine";
import type { ChatNode } from "@/lib/flow";
import { flow } from "@/lib/flow";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

export async function answerUnknown(txt:string){
  const r = await openai.chat.completions.create({
    model:"gpt-3.5-turbo",
    temperature:0.7,
    messages:[
      {role:"system",content:"–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Å–≤–∞–¥–µ–±–Ω—ã–π –±–æ—Ç-–∫–æ–Ω—Å—å–µ—Ä–∂. –ò–∑–≤–∏–Ω–∏—Å—å –∏ —Å–∫–∞–∂–∏, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ –Ω–µ—Ç."},
      {role:"user",content:txt}
    ],
  });
  return r.choices[0].message?.content ?? "–ò–∑–≤–∏–Ω–∏—Ç–µ, —É –º–µ–Ω—è –Ω–µ—Ç —Ç–∞–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ üôà";
}

/* ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helper ‚îÄ‚îÄ */
function fill(raw: string, ctx: any, userText: string) {
  // if the template is literally "{intro}" and ctx.intro exists ‚Üí use it
  let txt = raw === "{intro}" && ctx.intro ? ctx.intro : raw;

  if (raw === "{intro}" && !ctx.intro) {
    txt = `–ü—Ä–∏–≤–µ—Ç, ${ctx.name}!`;
  }

  // simple placeholders
  return txt
    .replace(/<name>/g,  ctx.name ?? "")
    .replace(/<diet>/g,  ctx.diet ?? "")
    .replace(/<stays>/g, ctx.stays ? "–æ—Å—Ç–∞–µ—Ç—Å—è —Å –Ω–æ—á—ë–≤–∫–æ–π" : "")
    .replace(/<input>/g, userText);           // if you ever need last answer
}

export async function renderNode(node: ChatNode, ctx: any, userText: string) {
  const raw = Array.isArray(node.template)
    ? node.template[Math.floor(Math.random() * node.template.length)]
    : node.template;
  const compiled = fill(raw, ctx, userText);

  if (node.useGPT === false) {
    if (node.concierge) return [{ role: "bot", text: compiled, type: "concierge", ...node.concierge }];
    
    const out: any[] = [{ role: "bot", type: "text", text: compiled }];
    if (node.info) out.push({ role: "bot", type: "info", ...node.info });
    return out;
  }

  /* GPT as a ‚Äòglue‚Äô layer: forward userText, but keep story prompt locked */
  const r = await openai.chat.completions.create({
    model: "gpt-4o-mini",
    temperature: 0.7,
    messages: [
      { role: "system", content: compiled },
      { role: "user", content: userText },
    ],
  });
  return [{ role: "bot", type: "text", text: r.choices[0].message?.content ?? "" }];
}

/**
 * Core runner: single request‚Äìresponse cycle.
 * Handles `ctx.seen` + ‚Äúresume‚Äù sentinel.
 */
export async function runFlow(stateId: string, input: string, ctx: any) {
  // ensure ctx.seen exists
  if (!Array.isArray(ctx.seen)) ctx.seen = [] as string[];
  if (!Array.isArray(ctx.states)) ctx.states = [] as any[];

  /* ‚îÄ‚îÄ 0. init engine ‚îÄ‚îÄ */
  const engine = new FlowEngine(stateId);
  let userInput = input.trim();

  /* ‚îÄ‚îÄ 1. advance immediately if user typed —á—Ç–æ‚Äë—Ç–æ ‚îÄ‚îÄ */
  if (userInput) {
    const currentNode = engine.node();
    const expectsButton = currentNode.buttons?.length;
    const expectsFree   = !currentNode.auto && !expectsButton; // —É–∑–µ–ª –∂–¥–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã–π –≤–≤–æ–¥

    if (expectsButton || expectsFree) {
      engine.advance(userInput, ctx);
      userInput = ""; // consume once
    }

    //if (currentNode.tag) ctx.seen.push(currentNode.tag);
  }

  /* ‚îÄ‚îÄ 2. build bot messages until –æ—Å—Ç–∞–Ω–æ–≤–∏–º—Å—è ‚îÄ‚îÄ */
  const messages: any[] = [];
  for (let guard = 0; guard < 30; guard++) {
    const node = engine.node();
    if (!node) break; // corrupted id

    /* skip duplicate topics */
    if (node.tag && ctx.seen.includes(node.tag)) {
      if (!node.inquiry && node.tag)
        messages.push(...(await renderNode(node, ctx, userInput)));
      engine.advance("", ctx);
      continue;
    }

    /* render */
    messages.push(...(await renderNode(node, ctx, userInput)));
    if (node.delayMs)
      messages.push({ role: "bot", type: "typing", delayMs: node.delayMs });

    /* if node is auto ‚Üí jump –¥–∞–ª—å—à–µ –∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ü–∏–∫–ª */
    if (node.auto) {
      engine.advance("", ctx);
      continue;
    }

    /* interactive node: stop here */
    return {
      state: engine.id(),
      buttons: node.buttons ?? [],
      messages,
    };
  }

  /* ‚îÄ‚îÄ safety fallback ‚îÄ‚îÄ */
  return {
    state: engine.id(),
    buttons: [],
    messages,
  };
}